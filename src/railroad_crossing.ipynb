{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impaired-original",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing servos and torch\n",
    "from SCSCtrl import TTLServo\n",
    "import torch\n",
    "# Setting camera little bit lower if it is not yet\n",
    "TTLServo.servoAngleCtrl(5,10,1,150)\n",
    "# Transfer the device from CPU memory to the GPU device\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enclosed-lambda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing TRT optimized models\n",
    "from torch2trt import TRTModule\n",
    "\n",
    "model_road = TRTModule()\n",
    "model_road.load_state_dict(torch.load('best_steering_model_xy_trt.pth')) # well trained road following model\n",
    "\n",
    "model_collision = TRTModule()\n",
    "model_collision.load_state_dict(torch.load('best_model_trt.pth')) # well trained collision avoidance model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annoying-threat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is from road_following/live_demo.ipynb\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "# Converting models to match camera\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "middle-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting camera, also its from jetbot own notebooks\n",
    "from IPython.display import display\n",
    "import ipywidgets\n",
    "import traitlets\n",
    "from jetbot import Camera, bgr8_to_jpeg\n",
    "\n",
    "camera = Camera()\n",
    "\n",
    "image_widget = ipywidgets.Image()\n",
    "\n",
    "traitlets.dlink((camera, 'value'), (image_widget, 'value'), transform=bgr8_to_jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-browser",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing tobot to control motors\n",
    "from jetbot import Robot\n",
    "\n",
    "robot = Robot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "phantom-assumption",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Road following sliders\n",
    "speed_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01, description='speed gain')\n",
    "steering_gain_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, step=0.01,  description='steering gain')\n",
    "steering_dgain_slider = ipywidgets.FloatSlider(min=0.0, max=0.5, step=0.001,description='steering kd')\n",
    "steering_bias_slider = ipywidgets.FloatSlider(min=-0.3, max=0.3, step=0.01, description='steering bias')\n",
    "\n",
    "display(speed_gain_slider, steering_gain_slider, steering_dgain_slider, steering_bias_slider)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "earned-sperm",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collision avoidance sliders\n",
    "stop_slider = ipywidgets.FloatSlider(min=0.0, max=1.0, orientation='vertical',description='stop')\n",
    "\n",
    "display(ipywidgets.HBox([stop_slider]))\n",
    "display(image_widget)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-arnold",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing all needed stuff\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from SCSCtrl import TTLServo\n",
    "import torch.nn.functional as F\n",
    "import time\n",
    "import math\n",
    "\n",
    "angle = 0.0\n",
    "angle_last = 0.0\n",
    "\n",
    "def railroad_crossing(imageInput):\n",
    "    # Global variables\n",
    "    global angle, angle_last, stop_slider, robot\n",
    "    global speed_value, steering_bias, steering_gain, steering_dgain\n",
    "    # Preprocessed road following model\n",
    "    xy = model_road(preprocess(imageInput)).detach().float().cpu().numpy().flatten()\n",
    "    x = xy[0]\n",
    "    y = (0.5 - xy[1]) / 2.0\n",
    "    # Slider values for road following model\n",
    "    speed_value = speed_gain_slider.value\n",
    "    steering_bias = steering_bias_slider.value\n",
    "    steering_gain = steering_gain_slider.value\n",
    "    steering_dgain = steering_dgain_slider.value\n",
    "    # Preprocessed collision avoidance model\n",
    "    prob_stop = float(F.softmax(model_collision(preprocess(imageInput)), dim=1).flatten()[0])\n",
    "    # Slider value for stop from collision avoidance\n",
    "    stop_slider.value = prob_stop\n",
    "    # Image to hsv color space\n",
    "    hsv = cv.cvtColor(imageInput, cv.COLOR_BGR2HSV)\n",
    "    # Values for yellow, because train have yellow color and stop background dont have that color\n",
    "    colorUpperYellow = np.array([44, 255, 255])\n",
    "    colorLowerYellow = np.array([24, 100, 100])\n",
    "    # Values for blue, because train have blue color and stop background dont have that color\n",
    "    colorUpperBlue = np.array([140, 255, 255])\n",
    "    colorLowerBlue = np.array([100, 50, 50])\n",
    "    \n",
    "    # Mask for both colors\n",
    "    maskYellow = cv.inRange(hsv, colorLowerYellow, colorUpperYellow)\n",
    "    maskBlue = cv.inRange(hsv, colorLowerBlue, colorUpperBlue)\n",
    "    # Restoring bigger and smaller areas for both masks\n",
    "    maskYellow = cv.erode(maskYellow, None, iterations=2)\n",
    "    maskYellow = cv.dilate(maskYellow, None, iterations=2)\n",
    "    maskBlue = cv.erode(maskBlue, None, iterations=2)\n",
    "    maskBlue = cv.dilate(maskBlue, None, iterations=2)\n",
    "    # Creating one mask which contains both colors separately or together\n",
    "    mask = cv.bitwise_or(maskBlue, maskYellow)\n",
    "    # Obtaining the conformed area contour\n",
    "    cnts = cv.findContours(mask.copy(), cv.RETR_EXTERNAL,\n",
    "        cv.CHAIN_APPROX_SIMPLE)[-2]\n",
    "    # If robot is in right place and there is no train coming it just stops\n",
    "    if prob_stop < 0.05:\n",
    "        # All values to 0 because then robot dont move\n",
    "        robot.right_motor.value = 0.0\n",
    "        robot.right_motor.value = 0.0\n",
    "        x = 0.0\n",
    "        y = 0.0\n",
    "        speed_value = 0\n",
    "        steering_value = 0\n",
    "        steering_gain = 0\n",
    "\n",
    "    # If robot is in right place and there is train coming\n",
    "    if len(cnts) > 0 and prob_stop < 0.05:\n",
    "        # All values to 0 because then robot dont move\n",
    "        robot.right_motor.value = 0.0\n",
    "        robot.right_motor.value = 0.0\n",
    "        x = 0.0\n",
    "        y = 0.0\n",
    "        speed_value = 0\n",
    "        steering_value = 0\n",
    "        steering_gain = 0\n",
    "        # Finding the largest contour area\n",
    "        flag_area = max(cnts, key=cv.contourArea)\n",
    "        # Changing mask values to work better with image\n",
    "        mask = cv.bitwise_not(mask)\n",
    "        mask = cv.bitwise_and(imageInput,imageInput, mask=mask)\n",
    "        # Creating rectangle for the recognised color\n",
    "        (xg,yg,wg,hg) = cv.boundingRect(flag_area)\n",
    "        cv.rectangle(imageInput,(xg,yg),(xg+wg, yg+hg),(0,255,0),2)\n",
    "        # Servos do the movement\n",
    "        TTLServo.servoAngleCtrl(2, 30, 1, 500)\n",
    "        TTLServo.servoAngleCtrl(3, -30, 1, 500)\n",
    "    # If colors that train have are not found then servos are on normal state\n",
    "    else:\n",
    "        TTLServo.servoAngleCtrl(2, 0, 1, 150)\n",
    "        TTLServo.servoAngleCtrl(3, 0, 1, 150)\n",
    "    # Values from road following notebook to get robot move properly\n",
    "    angle = np.arctan2(x, y)\n",
    "    pid = angle * steering_gain + (angle - angle_last) * steering_dgain\n",
    "    angle_last = angle\n",
    "    steering_value = pid + steering_bias\n",
    "\n",
    "    robot.left_motor.value = max(min(speed_value + steering_value, 1.0), 0.0)\n",
    "    robot.right_motor.value = max(min(speed_value - steering_value, 1.0), 0.0)\n",
    "\n",
    "\n",
    "    return imageInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "heated-satisfaction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# executing new camera frame\n",
    "def execute(change):\n",
    "    global image_widget\n",
    "    image = change['new']\n",
    "    image_widget.value = bgr8_to_jpeg(railroad_crossing(image))\n",
    "    \n",
    "execute({'new': camera.value})\n",
    "camera.unobserve_all()\n",
    "camera.observe(execute, names='value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prescription-freedom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shutting robot and camera down\n",
    "import time\n",
    "\n",
    "camera.unobserve(execute, names='value')\n",
    "\n",
    "time.sleep(0.1)  # add a small sleep to make sure frames have finished processing\n",
    "\n",
    "robot.stop()\n",
    "camera.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upper-canal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
